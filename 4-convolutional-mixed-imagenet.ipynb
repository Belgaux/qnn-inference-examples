{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<QNN.layers.QNNConvolutionLayer at 0x7f77cc02ce50>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77aded79d0>,\n",
       " <QNN.layers.QNNPoolingLayer at 0x7f77ade67110>,\n",
       " <QNN.layers.QNNConvolutionLayer at 0x7f77ade67210>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77ade672d0>,\n",
       " <QNN.layers.QNNPoolingLayer at 0x7f77ade67390>,\n",
       " <QNN.layers.QNNConvolutionLayer at 0x7f77ade67410>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77ade674d0>,\n",
       " <QNN.layers.QNNConvolutionLayer at 0x7f77ade67510>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77ade675d0>,\n",
       " <QNN.layers.QNNConvolutionLayer at 0x7f77ade67610>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77ade676d0>,\n",
       " <QNN.layers.QNNPoolingLayer at 0x7f77ade67710>,\n",
       " <QNN.layers.QNNFullyConnectedLayer at 0x7f77ade67750>,\n",
       " <QNN.layers.QNNThresholdingLayer at 0x7f77ade677d0>,\n",
       " <QNN.layers.QNNFullyConnectedLayer at 0x7f77ade67850>,\n",
       " <QNN.layers.QNNScaleShiftLayer at 0x7f77ade678d0>,\n",
       " <QNN.layers.QNNReLULayer at 0x7f77ade67a10>,\n",
       " <QNN.layers.QNNFullyConnectedLayer at 0x7f77ade67a50>,\n",
       " <QNN.layers.QNNScaleShiftLayer at 0x7f77ade67ad0>,\n",
       " <QNN.layers.QNNSoftmaxLayer at 0x7f77ade67c10>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from QNN.layers import *\n",
    "import pickle\n",
    "\n",
    "!wget -nc http://www.idi.ntnu.no/~yamanu/alexnet-hwgq.pickle\n",
    "qnn = pickle.load(open(\"alexnet-hwgq.pickle\", \"rb\"))\n",
    "\n",
    "qnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imagenet_data.classes import *\n",
    "len(imagenet_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=227x227 at 0x7F77A9A30A70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[-30., -36., -39., ..., -43., -52., -60.],\n",
       "        [-31., -36., -36., ..., -47., -53., -56.],\n",
       "        [-39., -38., -35., ..., -42., -53., -48.],\n",
       "        ..., \n",
       "        [-35., -20., -56., ..., -50., -27., -69.],\n",
       "        [-30., -47.,  38., ..., -26.,  -5., -27.],\n",
       "        [ 19., -64.,  -7., ...,  -4., -85.,   9.]],\n",
       "\n",
       "       [[ 34.,  30.,  29., ...,  13.,  -7., -12.],\n",
       "        [ 34.,  30.,  30., ...,   6., -12., -10.],\n",
       "        [ 32.,  28.,  31., ...,  11.,  -9.,  -4.],\n",
       "        ..., \n",
       "        [-14.,  20., -58., ...,  -3.,  32., -33.],\n",
       "        [ 14., -15.,  65., ...,  18.,  35.,  13.],\n",
       "        [ 39., -35.,  35., ...,  50., -46.,  34.]],\n",
       "\n",
       "       [[ 21.,  13.,  14., ...,  -6., -31., -38.],\n",
       "        [ 21.,  13.,  13., ..., -12., -35., -36.],\n",
       "        [ 21.,  11.,  12., ...,  -6., -30., -25.],\n",
       "        ..., \n",
       "        [  4.,  57., -12., ...,  15.,   6.,   5.],\n",
       "        [ 29.,  22.,  78., ...,  37.,  42.,  44.],\n",
       "        [ 49.,  -4.,  32., ...,  41., -11.,  46.]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=227x227 at 0x7F77A9A07CF8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[  -2.,   10.,   20., ...,  -80.,  -78.,  -77.],\n",
       "        [  -1.,   11.,   23., ...,  -81.,  -79.,  -77.],\n",
       "        [   0.,   15.,   25., ...,  -77.,  -78.,  -78.],\n",
       "        ..., \n",
       "        [ -90.,  -90.,  -86., ...,  -56.,  -60.,  -58.],\n",
       "        [ -96.,  -92.,  -88., ...,  -53.,  -59.,  -59.],\n",
       "        [ -95.,  -95.,  -90., ...,  -57.,  -55.,  -56.]],\n",
       "\n",
       "       [[   6.,   20.,   31., ...,  -85.,  -85.,  -85.],\n",
       "        [   7.,   21.,   32., ...,  -86.,  -86.,  -84.],\n",
       "        [   6.,   20.,   33., ...,  -88.,  -86.,  -84.],\n",
       "        ..., \n",
       "        [-110., -102.,  -87., ...,  -54.,  -57.,  -52.],\n",
       "        [-109., -102.,  -92., ...,  -50.,  -51.,  -54.],\n",
       "        [-108., -106.,  -94., ...,  -48.,  -47.,  -50.]],\n",
       "\n",
       "       [[  21.,   36.,   53., ...,  -84.,  -86.,  -82.],\n",
       "        [  22.,   37.,   54., ...,  -85.,  -87.,  -83.],\n",
       "        [  21.,   37.,   55., ...,  -84.,  -83.,  -87.],\n",
       "        ..., \n",
       "        [-119., -104.,  -81., ...,  -28.,  -27.,  -23.],\n",
       "        [-115., -104.,  -89., ...,  -27.,  -29.,  -29.],\n",
       "        [-108., -102.,  -86., ...,  -26.,  -21.,  -21.]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=227x227 at 0x7F77A9A30A70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[[-62., -61., -55., ...,  -9., -45., -40.],\n",
       "        [-61., -52., -53., ..., -68., -26.,  40.],\n",
       "        [-68., -78., -71., ...,  82.,  43.,  55.],\n",
       "        ..., \n",
       "        [ 17.,  -7.,  -7., ..., -26., -36.,   0.],\n",
       "        [-18., -10., -29., ..., -18., -26.,   3.],\n",
       "        [ 37., -34.,  66., ..., -58.,  64., -27.]],\n",
       "\n",
       "       [[-76., -75., -69., ..., -23., -50., -52.],\n",
       "        [-72., -66., -65., ..., -82., -31.,  32.],\n",
       "        [-75., -85., -78., ...,  74.,  38.,  56.],\n",
       "        ..., \n",
       "        [ 18.,  -5.,  -5., ..., -27., -35.,  -8.],\n",
       "        [-15.,  -9., -28., ..., -19., -25.,  -8.],\n",
       "        [ 44., -33.,  64., ..., -55.,  66., -34.]],\n",
       "\n",
       "       [[-96., -95., -85., ..., -39., -67., -67.],\n",
       "        [-90., -82., -80., ..., -98., -48.,  17.],\n",
       "        [-86., -96., -89., ...,  59.,  25.,  44.],\n",
       "        ..., \n",
       "        [  6., -15., -15., ..., -33., -45., -15.],\n",
       "        [-28., -19., -38., ..., -25., -35., -14.],\n",
       "        [ 33., -41.,  55., ..., -62.,  56., -41.]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# define a small utility function to first display, then prepare the\n",
    "# images for classification\n",
    "def prepare_gtsrb(img):\n",
    "    # make sure the image is the size expected by the network\n",
    "    img = img.resize((227, 227))\n",
    "    display(img)\n",
    "    # convert to numpy array\n",
    "    img = np.asarray(img).copy().astype(np.float32)\n",
    "    # we need the data layout to be (channels, rows, columns)\n",
    "    # but it comes in (rows, columns, channels) format, so we\n",
    "    # need to transpose the axes:\n",
    "    img = img.transpose((2, 0, 1))\n",
    "        \n",
    "    # our network is trained with BGR instead of RGB images,\n",
    "    # so we need to invert the order of channels in the channel axis:\n",
    "    img = img[::-1, :, :]\n",
    "    # finally, we need to subtract the mean per-channel pixel intensity\n",
    "    # since this is how this network has been trained\n",
    "    img[0] = img[0] - 104\n",
    "    img[1] = img[1] - 117\n",
    "    img[2] = img[2] - 123\n",
    "    return img\n",
    "\n",
    "# load test images and prepare them\n",
    "img_grouse = prepare_gtsrb(Image.open(\"imagenet_data/grouse.jpg\"))\n",
    "display(img_grouse)\n",
    "img_cat = prepare_gtsrb(Image.open(\"imagenet_data/cat.jpg\"))\n",
    "display(img_cat)\n",
    "img_husky = prepare_gtsrb(Image.open(\"imagenet_data/husky.jpg\"))\n",
    "display(img_husky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imagenet_predict(img):\n",
    "    # get the predictions array\n",
    "    res = predict(qnn, img)\n",
    "    # return the index of the largest prediction, then use the\n",
    "    # classes array to map to a human-readable string\n",
    "    winner_ind = np.argmax(res)\n",
    "    winner_class = imagenet_classes[winner_ind]\n",
    "    # the sum of the output values add up to 1 due to softmax,\n",
    "    # so we can interpret them as probabilities\n",
    "    winner_prob = 100 * res[winner_ind]\n",
    "    print(\"The QNN predicts this is a %s (class %d) with %f percent probability\" % (winner_class, winner_ind, winner_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The QNN predicts this is a black grouse (class 80) with 98.129130 percent probability\n",
      "The QNN predicts this is a Egyptian cat (class 285) with 30.018796 percent probability\n",
      "The QNN predicts this is a Eskimo dog, husky (class 248) with 59.245122 percent probability\n"
     ]
    }
   ],
   "source": [
    "imagenet_predict(img_grouse)\n",
    "imagenet_predict(img_cat)\n",
    "imagenet_predict(img_husky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
